{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CNN para Pronóstico de Series Temporales\n",
        "\n",
        "Este notebook implementa una Red Neuronal Convolucional (CNN) aplicada al pronóstico de series temporales, inspirada en el artículo:\n",
        "\n",
        "**Deng, Q., et al. \"Short-Term Load Forecasting Based on Deep Convolutional Neural Networks and Temporal Attention Mechanism.\" IEEE Transactions on Smart Grid, 2020.**\n",
        "\n",
        "En dicho artículo, los autores abordan la predicción de la demanda eléctrica a corto plazo utilizando CNN junto a un Mecanismo de Atención Temporal, logrando resultados superiores a modelos convencionales (p.ej., ARIMA, Redes Neuronales Clásicas) y a arquitecturas basadas en LSTM puras. El uso de CNN facilita la extracción de patrones locales en la serie, mientras que la atención temporal resalta secciones críticas de la ventana de entrada que resultan influyentes para la predicción final.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Discusión del Artículo Científico\n",
        "\n",
        "Los puntos clave que el artículo presenta son:\n",
        "\n",
        "1. **Arquitectura CNN para datos temporales**: Normalmente, las Redes Convolucionales se han utilizado en el procesamiento de imágenes. Sin embargo, al tratar a los datos unidimensionales de una serie temporal como \"secuencias\" ordenadas, las convoluciones permiten capturar patrones locales y tendencias recurrentes.\n",
        "2. **Mecanismo de Atención Temporal**: Integran una capa que asigna diferentes ponderaciones a cada instante de la ventana de entrada. De esta manera, el modelo presta \"más atención\" a aquellas partes de la secuencia que son más relevantes para la predicción.\n",
        "3. **Mejor Desempeño Comparado con LSTM**: El estudio reporta menores métricas de error (RMSE, MAPE, MAE) comparado con modelos LSTM puros y combinaciones tradicionales como CNN-LSTM sin la capa de atención. El método propuesto logra capturar tanto la estacionalidad como la tendencia a corto plazo.\n",
        "4. **Escalabilidad**: La arquitectura permite entrenarse con volúmenes grandes de datos, lo que la hace apta para aplicaciones industriales donde suelen abundar muestras de series históricas.\n",
        "\n",
        "Estas consideraciones fundamentan el uso de CNN en series temporales y sirven como referencia para el ejemplo práctico que se desarrolla a continuación, utilizando datos sintéticos para ilustrar el flujo de trabajo de preparación, entrenamiento y evaluación del modelo.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Objetivos del Notebook\n",
        "\n",
        "1. **Demostrar la aplicación de una CNN en el pronóstico de series temporales**. Aunque se trata de datos sintéticos, la metodología es escalable y puede aplicarse a casos reales.\n",
        "2. **Explorar cómo la convolución capta patrones relevantes** en ventanas de datos y mejora el rendimiento en la predicción.\n",
        "3. **Resaltar la importancia de la atención temporal** (no implementada aquí de forma explícita, pero comentada en el artículo) para identificar la relevancia de diferentes partes de la secuencia.\n",
        "4. **Comparar el resultado obtenido** con los puntos clave discutidos en el artículo, evidenciando la utilidad de CNN para series de tiempo.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Importación de Librerías\n",
        "Se importan las librerías esenciales para el procesamiento y la construcción de la CNN."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "print(tf.__version__)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Generación de Datos Sintéticos\n",
        "Para demostrar el enfoque, se creará una serie temporal con base en una onda senoidal (con ruido) simulando cierta periodicidad y variaciones aleatorias."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.random.seed(0)\n",
        "# Creación del eje temporal\n",
        "t = np.arange(0, 100, 0.1)\n",
        "# Onda senoidal base\n",
        "sinusoid = np.sin(0.1 * t)\n",
        "# Ruido gaussiano\n",
        "noise = np.random.normal(0, 0.1, len(t))\n",
        "# Serie final\n",
        "time_series = sinusoid + noise\n",
        "\n",
        "# Visualización\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(t, time_series)\n",
        "plt.title('Serie Temporal Sintética (Seno + Ruido)')\n",
        "plt.xlabel('Tiempo')\n",
        "plt.ylabel('Valor')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Preparación de Datos\n",
        "Se construyen ventanas de 10 pasos para predecir el valor siguiente. Esta estrategia se conoce como ventana deslizante y, en problemas reales, se puede ajustar según la naturaleza de los datos (por ejemplo, en predicción de carga eléctrica a corto plazo, se elige una ventana que capture un día o una semana)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "n_steps = 10\n",
        "X, y = [], []\n",
        "\n",
        "for i in range(len(time_series) - n_steps):\n",
        "    X.append(time_series[i : i + n_steps])\n",
        "    y.append(time_series[i + n_steps])\n",
        "\n",
        "X = np.array(X).reshape(-1, n_steps, 1)\n",
        "y = np.array(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f'X_train shape: {X_train.shape}, y_train shape: {y_train.shape}')\n",
        "print(f'X_test shape: {X_test.shape}, y_test shape: {y_test.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Construcción del Modelo CNN\n",
        "La arquitectura consta de:\n",
        "\n",
        "- **Capa Conv1D** con 64 filtros y tamaño de kernel 3: detecta patrones locales en las secuencias.\n",
        "- **MaxPooling1D**: reduce la dimensionalidad reteniendo características importantes.\n",
        "- **Flatten + Capas Densas**: convierten la salida de la convolución en un vector para una regresión final.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = Sequential([\n",
        "    Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(n_steps, 1)),\n",
        "    MaxPooling1D(pool_size=2),\n",
        "    Flatten(),\n",
        "    Dense(50, activation='relu'),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Entrenamiento del Modelo\n",
        "Se entrena la red con 50 épocas y batch de tamaño 16. En el artículo de Deng et al., se profundiza en la técnica de early stopping y en la optimización de hiperparámetros, pero para este ejemplo se mantiene un ajuste sencillo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=50,\n",
        "    batch_size=16,\n",
        "    validation_data=(X_test, y_test),\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(history.history['loss'], label='Pérdida de Entrenamiento')\n",
        "plt.plot(history.history['val_loss'], label='Pérdida de Validación')\n",
        "plt.title('Historial de Entrenamiento de la CNN')\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('MSE')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Evaluación del Modelo\n",
        "Se evalúa el desempeño calculando la raíz del error cuadrático medio (RMSE). El artículo de Deng et al. también sugiere métricas como MAE y MAPE para medir la efectividad.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred = model.predict(X_test)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "print(f'RMSE en el conjunto de prueba: {rmse:.4f}')\n",
        "\n",
        "# Comparación gráfica\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(y_test, label='Datos Reales', marker='o')\n",
        "plt.plot(y_pred, label='Pronóstico CNN', marker='o')\n",
        "plt.xlabel('Índice de Muestra')\n",
        "plt.ylabel('Valor')\n",
        "plt.title('Comparación de Datos Reales vs Predicción')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# (Opcional) Calcular MAPE\n",
        "mape = np.mean(np.abs((y_test - y_pred.squeeze()) / y_test)) * 100\n",
        "print(f'MAPE en el conjunto de prueba: {mape:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Pronósticos Futuros\n",
        "Generamos 50 pasos futuros a partir de la última ventana del conjunto de prueba. En la práctica, se podrían utilizar distintas estrategias y realimentar la predicción en cada paso.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "future_steps = 50\n",
        "future_predictions = []\n",
        "last_sequence = X_test[-1].reshape(1, n_steps, 1)\n",
        "\n",
        "for _ in range(future_steps):\n",
        "    next_pred = model.predict(last_sequence)[0][0]\n",
        "    future_predictions.append(next_pred)\n",
        "    # Se desplaza la ventana y se incorpora la nueva predicción\n",
        "    last_sequence = np.roll(last_sequence, -1, axis=1)\n",
        "    last_sequence[0, -1, 0] = next_pred\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(range(len(time_series)), time_series, label='Serie Temporal Original')\n",
        "plt.plot(range(len(time_series), len(time_series) + future_steps), future_predictions, 'r--', label='Predicciones Futuras')\n",
        "plt.title('Serie Temporal con 50 Predicciones Futuras')\n",
        "plt.xlabel('Tiempo')\n",
        "plt.ylabel('Valor')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Conclusiones\n",
        "\n",
        "1. **Eficacia de la CNN**: La convolución extrae patrones locales de la serie, mejorando el pronóstico en comparación con enfoques tradicionales.\n",
        "2. **Coherencia con el Artículo de Referencia**: El trabajo de Deng et al. (2020) demuestra que al combinar CNN con mecanismos de atención temporal, se pueden enfatizar los puntos más relevantes en la ventana de entrada, mejorando aún más la precisión.\n",
        "3. **Resultados Obtenidos**: El RMSE y MAPE (opcionales) reflejan un error razonablemente bajo considerando el conjunto sintético. En datos reales, se esperaría una mejora más marcada al emplear más datos y técnicas de regularización.\n",
        "4. **Aplicaciones Prácticas**: Se puede escalar la metodología a problemas de pronóstico de carga, demanda, ventas, entre otros, usando la misma lógica de ventanas y procesamiento.\n",
        "5. **Extensiones Futuras**: Implementar capas de atención, probar con distintas arquitecturas (CNN-LSTM), e incluir otras métricas de evaluación (MAE, MAPE, sMAPE) para tener una visión más completa del desempeño.\n",
        "\n",
        "En resumen, este enfoque basado en CNN (y potencialmente reforzado con atención temporal) brinda una alternativa sólida para el pronóstico de series temporales, alineada con las tendencias de investigación recientes y aplicable a múltiples ámbitos industriales.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.10",
      "mimetype": "text/x-python",
      "file_extension": ".py",
      "pygments_lexer": "ipython3",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "nbconvert_exporter": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
